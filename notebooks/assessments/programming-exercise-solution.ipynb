{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protest Classification Exercise - SOLUTION\n",
    "## Complete Implementation with Two Models\n",
    "\n",
    "**Models Used**: Logistic Regression and Random Forest\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmatekenya/My Drive (dmatekenya@gmail.com)/TEACHING/AIMS-DSCBI/.venv-llms/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# ==================\n",
    "# SETUP INPUT\n",
    "# ==================\n",
    "DIR_DATA = Path.cwd().parents[1] / \"data\"\n",
    "FILE_PROTESTS = DIR_DATA / \"conflict/protests_filtered.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# PTS: 1\n",
    "df = pd.read_csv(FILE_PROTESTS)\n",
    "\n",
    "# Combine notes and description\n",
    "# PTS: 2\n",
    "df['text'] = df['notes'] + ' ' + df['description']\n",
    "\n",
    "# Check data\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nCategories:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nSample text: {df['text'].iloc[0][:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 1 2 3 4 5]\n",
      "Label mapping: {0: 'Business and legal', 1: 'Climate and environment', 2: 'Livelihood (Prices, jobs and salaries)', 3: 'Political/Security', 4: 'Public service delivery', 5: 'Social'}\n"
     ]
    }
   ],
   "source": [
    "# Encode target labels\n",
    "# PTS: 2\n",
    "# If the trainer used another method (e.g., pd.factorize() or dictionary mapping), \n",
    "# that's acceptable too as long as the labels are correctly encoded.\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['category'])\n",
    "\n",
    "print(f\"Encoded labels: {np.unique(y)}\")\n",
    "print(f\"Label mapping: {dict(enumerate(le.classes_))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model with TF-IDF (10 minutes)\n",
    "\n",
    "**What is TF-IDF?**\n",
    "- **TF** (Term Frequency): How often a word appears in a document\n",
    "- **IDF** (Inverse Document Frequency): How rare/common a word is across all documents\n",
    "- **Result**: Important words get high scores, common words (like \"the\") get low scores\n",
    "- **Example**: \"protest\" appears often in one document but not all â†’ high TF-IDF score\n",
    "\n",
    "TF-IDF converts text into numbers that capture word importance, making it possible for ML models to work with text.\n",
    "\n",
    "ðŸ“š **Learn more**: [TfidfVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 179\n",
      "Test samples: 45\n"
     ]
    }
   ],
   "source": [
    "# Split data (80/20)\n",
    "# PTS: 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'].values,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (179, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import other necessary libraries\n",
    "\n",
    "# TODO: Create TF-IDF features\n",
    "# PTS: 5\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TF-IDF Results:\n",
      "   Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train Random Forest model\n",
    "# Initialize model\n",
    "# PTS: 4\n",
    "model_tfidf = RandomForestClassifier(random_state=42)\n",
    "# YOUR CODE - fit the model\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# TODO: Predict and evaluate\n",
    "# PTS: 4\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "# Calculate accuracy\n",
    "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"\\n TF-IDF Results:\")\n",
    "print(f\"   Accuracy: {acc_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model with Embeddings (12 minutes)\n",
    "\n",
    "**What are Sentence Embeddings?**\n",
    "- Convert entire sentences/paragraphs into dense vectors (fixed-size arrays of numbers)\n",
    "- Capture **semantic meaning**: \"protest rally\" and \"demonstration\" will have similar vectors\n",
    "- Pre-trained on huge datasets, so they understand context and synonyms\n",
    "- **all-MiniLM-L6-v2**: Lightweight model (384 dimensions, fast, good quality)\n",
    "\n",
    "**Key difference from TF-IDF:**\n",
    "- TF-IDF: Word frequency only â†’ \"protest\" and \"demonstration\" are completely different\n",
    "- Embeddings: Semantic meaning â†’ \"protest\" and \"demonstration\" are similar\n",
    "\n",
    "ðŸ“š **Learn more**: [Sentence Transformers documentation](https://www.sbert.net/docs/pretrained_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "\n",
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 61.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 79.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding shape: (179, 384)\n",
      "Embedding dimensions: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load lightweight embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "# PTS: 1\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"\\nEncoding training data...\")\n",
    "# PTS: 2\n",
    "X_train_embed = embedding_model.encode(X_train, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nEncoding test data...\")\n",
    "# PTS: 2\n",
    "X_test_embed = embedding_model.encode(X_test, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nEmbedding shape: {X_train_embed.shape}\")\n",
    "print(f\"Embedding dimensions: {X_train_embed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embeddings Results:\n",
      "   Accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train same model with embeddings\n",
    "#PTS: 4\n",
    "model_embed = RandomForestClassifier(random_state=42)\n",
    "model_embed.fit(X_train_embed, y_train)\n",
    "\n",
    "# TODO: Predict and evaluate\n",
    "# PTS: 4\n",
    "y_pred_embed = model_embed.predict(X_test_embed)\n",
    "acc_embed = accuracy_score(y_test, y_pred_embed)\n",
    "\n",
    "\n",
    "print(f\"\\nEmbeddings Results:\")``\n",
    "print(f\"   Accuracy: {acc_embed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare Results (5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL COMPARISON\n",
      "============================================================\n",
      "                    Method  Accuracy\n",
      "    TF-IDF + Random Forest  1.000000\n",
      "Embeddings + Random Forest  0.911111\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create comparison table\n",
    "# Create a DataFrame to compare results\n",
    "# one column for method, one for accuracy\n",
    "# PTS: 4\n",
    "results = pd.DataFrame({\n",
    "    'Method': ['TF-IDF + Random Forest', 'Embeddings + Random Forest'],\n",
    "    'Accuracy': [acc_tfidf, acc_embed]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 2 + 2 + 2 + 5 + 4 + 4 + 1 + 2 + 2 + 4 + 4 + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Points \n",
    "1 + 2 + 2 + 2 + 5 + 4 + 4 + 1 + 2 + 2 + 4 + 4 + 4 = 37\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
