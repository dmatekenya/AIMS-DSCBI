{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protest Classification Exercise - SOLUTION\n",
    "## Complete Implementation with Two Models\n",
    "\n",
    "**Models Used**: Logistic Regression and Random Forest\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmatekenya/My Drive (dmatekenya@gmail.com)/TEACHING/AIMS-DSCBI/.venv-llms/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# ==================\n",
    "# SETUP INPUT\n",
    "# ==================\n",
    "DIR_DATA =  Path.cwd().parents[0].joinpath(\"data\", \"conflict\")\n",
    "FILE_PROTESTS = DIR_DATA / \"protests_filtered.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (224, 4)\n",
      "\n",
      "Categories:\n",
      "category\n",
      "Livelihood (Prices, jobs and salaries)    64\n",
      "Political/Security                        56\n",
      "Business and legal                        42\n",
      "Social                                    26\n",
      "Public service delivery                   25\n",
      "Climate and environment                   11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample text: On 30 June 2024, retirees of Tehran steel industries staged a protest in front of the Steel Servants Pension Organization's office in Tehran - Distric...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(FILE_PROTESTS)\n",
    "\n",
    "# Combine notes and description\n",
    "df['text'] = df['notes'] + ' ' + df['description']\n",
    "\n",
    "# Check data\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nCategories:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nSample text: {df['text'].iloc[0][:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 1 2 3 4 5]\n",
      "Label mapping: {0: 'Business and legal', 1: 'Climate and environment', 2: 'Livelihood (Prices, jobs and salaries)', 3: 'Political/Security', 4: 'Public service delivery', 5: 'Social'}\n"
     ]
    }
   ],
   "source": [
    "# Encode target labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['category'])\n",
    "\n",
    "print(f\"Encoded labels: {np.unique(y)}\")\n",
    "print(f\"Label mapping: {dict(enumerate(le.classes_))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 179\n",
      "Test samples: 45\n"
     ]
    }
   ],
   "source": [
    "# Split data (80/20)\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['text'].values,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train_text)}\")\n",
    "print(f\"Test samples: {len(X_test_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (179, 1000)\n",
      "Number of features: 1000\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Number of features: {X_train_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Embedding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "\n",
      "Encoding training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding shape: (179, 384)\n",
      "Embedding dimensions: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load lightweight embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"\\nEncoding training data...\")\n",
    "X_train_embed = embedding_model.encode(X_train_text, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nEncoding test data...\")\n",
    "X_test_embed = embedding_model.encode(X_test_text, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nEmbedding shape: {X_train_embed.shape}\")\n",
    "print(f\"Embedding dimensions: {X_train_embed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Model 1 (Logistic Regression) with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression with TF-IDF...\n",
      "\n",
      "âœ… Logistic Regression (TF-IDF)\n",
      "   Accuracy: 1.0000\n",
      "   F1-Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression with TF-IDF\n",
    "print(\"Training Logistic Regression with TF-IDF...\")\n",
    "lr_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_lr_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "acc_lr_tfidf = accuracy_score(y_test, y_pred_lr_tfidf)\n",
    "f1_lr_tfidf = f1_score(y_test, y_pred_lr_tfidf, average='weighted')\n",
    "\n",
    "print(f\"\\nâœ… Logistic Regression (TF-IDF)\")\n",
    "print(f\"   Accuracy: {acc_lr_tfidf:.4f}\")\n",
    "print(f\"   F1-Score: {f1_lr_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train Model 1 (Logistic Regression) with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression with Embeddings...\n",
      "\n",
      "âœ… Logistic Regression (Embeddings)\n",
      "   Accuracy: 0.8000\n",
      "   F1-Score: 0.7479\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression with Embeddings\n",
    "print(\"Training Logistic Regression with Embeddings...\")\n",
    "lr_embed = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_embed.fit(X_train_embed, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_lr_embed = lr_embed.predict(X_test_embed)\n",
    "acc_lr_embed = accuracy_score(y_test, y_pred_lr_embed)\n",
    "f1_lr_embed = f1_score(y_test, y_pred_lr_embed, average='weighted')\n",
    "\n",
    "print(f\"\\nâœ… Logistic Regression (Embeddings)\")\n",
    "print(f\"   Accuracy: {acc_lr_embed:.4f}\")\n",
    "print(f\"   F1-Score: {f1_lr_embed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train Model 2 (Random Forest) with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest with TF-IDF...\n",
      "\n",
      "âœ… Random Forest (TF-IDF)\n",
      "   Accuracy: 1.0000\n",
      "   F1-Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest with TF-IDF\n",
    "print(\"Training Random Forest with TF-IDF...\")\n",
    "rf_tfidf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf_tfidf = rf_tfidf.predict(X_test_tfidf)\n",
    "acc_rf_tfidf = accuracy_score(y_test, y_pred_rf_tfidf)\n",
    "f1_rf_tfidf = f1_score(y_test, y_pred_rf_tfidf, average='weighted')\n",
    "\n",
    "print(f\"\\nâœ… Random Forest (TF-IDF)\")\n",
    "print(f\"   Accuracy: {acc_rf_tfidf:.4f}\")\n",
    "print(f\"   F1-Score: {f1_rf_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train Model 2 (Random Forest) with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest with Embeddings...\n",
      "\n",
      "âœ… Random Forest (Embeddings)\n",
      "   Accuracy: 0.9111\n",
      "   F1-Score: 0.8860\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest with Embeddings\n",
    "print(\"Training Random Forest with Embeddings...\")\n",
    "rf_embed = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_embed.fit(X_train_embed, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf_embed = rf_embed.predict(X_test_embed)\n",
    "acc_rf_embed = accuracy_score(y_test, y_pred_rf_embed)\n",
    "f1_rf_embed = f1_score(y_test, y_pred_rf_embed, average='weighted')\n",
    "\n",
    "print(f\"\\nâœ… Random Forest (Embeddings)\")\n",
    "print(f\"   Accuracy: {acc_rf_embed:.4f}\")\n",
    "print(f\"   F1-Score: {f1_rf_embed:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Compare All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL RESULTS COMPARISON\n",
      "======================================================================\n",
      "              Model Vectorization  Accuracy  F1-Score\n",
      "Logistic Regression        TF-IDF  1.000000  1.000000\n",
      "Logistic Regression    Embeddings  0.800000  0.747908\n",
      "      Random Forest        TF-IDF  1.000000  1.000000\n",
      "      Random Forest    Embeddings  0.911111  0.885989\n",
      "======================================================================\n",
      "\n",
      "ðŸ† BEST MODEL: Logistic Regression with TF-IDF\n",
      "   Accuracy: 1.0000\n",
      "   F1-Score: 1.0000\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create comparison dataframe\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Logistic Regression', 'Random Forest', 'Random Forest'],\n",
    "    'Vectorization': ['TF-IDF', 'Embeddings', 'TF-IDF', 'Embeddings'],\n",
    "    'Accuracy': [acc_lr_tfidf, acc_lr_embed, acc_rf_tfidf, acc_rf_embed],\n",
    "    'F1-Score': [f1_lr_tfidf, f1_lr_embed, f1_rf_tfidf, f1_rf_embed]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find best model\n",
    "best_idx = results['F1-Score'].idxmax()\n",
    "print(f\"\\nðŸ† BEST MODEL: {results.loc[best_idx, 'Model']} with {results.loc[best_idx, 'Vectorization']}\")\n",
    "print(f\"   Accuracy: {results.loc[best_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"   F1-Score: {results.loc[best_idx, 'F1-Score']:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Detailed Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from best model\n",
    "best_model_name = results.loc[best_idx, 'Model']\n",
    "best_vectorization = results.loc[best_idx, 'Vectorization']\n",
    "\n",
    "# Select the correct predictions based on best model\n",
    "if best_model_name == 'Logistic Regression' and best_vectorization == 'TF-IDF':\n",
    "    y_pred_best = y_pred_lr_tfidf\n",
    "elif best_model_name == 'Logistic Regression' and best_vectorization == 'Embeddings':\n",
    "    y_pred_best = y_pred_lr_embed\n",
    "elif best_model_name == 'Random Forest' and best_vectorization == 'TF-IDF':\n",
    "    y_pred_best = y_pred_rf_tfidf\n",
    "else:\n",
    "    y_pred_best = y_pred_rf_embed\n",
    "\n",
    "# Print detailed classification report\n",
    "print(f\"\\nDetailed Classification Report - {best_model_name} ({best_vectorization})\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_pred_best, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### Expected Observations:\n",
    "\n",
    "1. **Embeddings vs TF-IDF**: \n",
    "   - Embeddings usually perform better because they capture semantic meaning\n",
    "   - TF-IDF is faster but only captures word frequency\n",
    "\n",
    "2. **Model Comparison**:\n",
    "   - Logistic Regression is typically faster and works well with high-dimensional data\n",
    "   - Random Forest can capture non-linear patterns but may overfit on small datasets\n",
    "\n",
    "3. **Class Imbalance**:\n",
    "   - Some categories have fewer samples (e.g., Climate: 11 samples)\n",
    "   - F1-score is more informative than accuracy for imbalanced data\n",
    "   - Smaller classes may have lower precision/recall\n",
    "\n",
    "4. **Performance Tips**:\n",
    "   - With only 224 samples, simpler models (Logistic Regression) often work better\n",
    "   - Embeddings help when training data is limited\n",
    "   - Consider using class weights for imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "results.plot(x='Model', y='Accuracy', kind='bar', ax=ax1, color=['steelblue', 'lightcoral', 'mediumseagreen', 'orange'])\n",
    "ax1.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_xticklabels(results['Vectorization'], rotation=45)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.legend(['TF-IDF', 'Embeddings'])\n",
    "\n",
    "# F1-Score comparison\n",
    "results.plot(x='Model', y='F1-Score', kind='bar', ax=ax2, color=['steelblue', 'lightcoral', 'mediumseagreen', 'orange'])\n",
    "ax2.set_title('F1-Score Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('F1-Score', fontsize=12)\n",
    "ax2.set_xticklabels(results['Vectorization'], rotation=45)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.legend(['TF-IDF', 'Embeddings'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
